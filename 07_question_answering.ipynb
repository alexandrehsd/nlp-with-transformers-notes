{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Review-Based QA System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our QA system we’ll use the SubjQA dataset, which consists of more than 10,000 customer reviews in English about products and services in six domains: Trip‐Advisor, Restaurants, Movies, Books, Electronics, and Grocery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for subjqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/subjqa\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to focus on the Electronics domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "subjqa = load_dataset(\"subjqa\", name=\"electronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 1295\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 255\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n"
     ]
    }
   ],
   "source": [
    "print(subjqa[\"train\"][\"answers\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in train: 1295\n",
      "Number of questions in test: 358\n",
      "Number of questions in validation: 255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers.text</th>\n",
       "      <th>answers.answer_start</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>B005DKZTMG</td>\n",
       "      <td>Does the keyboard lightweight?</td>\n",
       "      <td>[this keyboard is compact]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>B00AAIPT76</td>\n",
       "      <td>How is the battery?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I bought this after the first spare gopro batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                        question                answers.text  \\\n",
       "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
       "1159  B00AAIPT76             How is the battery?                          []   \n",
       "\n",
       "     answers.answer_start                                            context  \n",
       "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
       "1159                   []  I bought this after the first spare gopro batt...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n",
    "for split, df in dfs.items():\n",
    "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")\n",
    " \n",
    "qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \"context\"]\n",
    "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the start index and length of the answer span to slice out the span of text in the review that corresponds to the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this keyboard is compact'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\n",
    "end_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\n",
    "sample_df[\"context\"].iloc[0][start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = {}\n",
    "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n",
    "for q in question_types:\n",
    "    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n",
    "pd.Series(counts).sort_values().plot.barh()\n",
    "plt.title(\"Frequency of Question Types\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the camera?\n",
      "How do you like the control?\n",
      "How fast is the charger?\n",
      "What is direction?\n",
      "What is the quality of the construction of the bag?\n",
      "What is your impression of the product?\n",
      "Is this how zoom works?\n",
      "Is sound clear?\n",
      "Is it a wireless keyboard?\n"
     ]
    }
   ],
   "source": [
    "for question_type in [\"How\", \"What\", \"Is\"]:\n",
    "    for question in (\n",
    "        dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)].sample(n=3, random_state=42)['question']):\n",
    "        print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Answers from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our training set is relatively small, with only 1,295 examples, a good strategy is to start with a language model that has already been fine-tuned on a large-scale QA dataset like SQuAD.\n",
    "\n",
    "This is somewhat different from what we've done previously. In Chapter 2, we had to fine-tune the classification head because the number of classes was tied to the dataset at hand. For extractive QA, we can actually start with a fine-tuned model since the structure of the labels remains the same across datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way to extract answers from text is by framing the problem as a span classification task, where the start and end tokens of an answer span act as the labels that a model needs to predict.\n",
    "\n",
    "As usual, the first thing we need is a tokenizer to encode our texts, so let’s take a look at how this works for QA tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing text for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How much music can this hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
    "file size.\"\"\"\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2129,  2172,  2189,  2064,  2023,  2907,  1029,   102,  2019,\n",
       "         23378,  2003,  2055,  1015, 16914,  1013,  3371,  1010,  2061,  2055,\n",
       "         25961,  2847,  5834,  2006,  5371,  2946,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2129,  2172,  2189,  2064,  2023,  2907,  1029,   102,  2019,\n",
       "        23378,  2003,  2055,  1015, 16914,  1013,  3371,  1010,  2061,  2055,\n",
       "        25961,  2847,  5834,  2006,  5371,  2946,  1012,   102])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our text is tokenized, we just need to instantiate the model with a QA head and run the inputs through the forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n",
      "         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n",
      "         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n",
      "         -2.3108, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n",
      "         -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,\n",
      "          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n",
      "         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 28])\n",
      "Start logits shape: torch.Size([1, 28])\n",
      "End logits shape: torch.Size([1, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input IDs shape: {inputs.input_ids.size()}\")\n",
    "print(f\"Start logits shape: {start_logits.size()}\")\n",
    "print(f\"End logits shape: {end_logits.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much music can this hold?\n",
      "Answer: 6000 hours\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "\n",
    "answer = tokenizer.decode(answer_span)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 19:27:05.509228: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/transformers/pipelines/question_answering.py:326: UserWarning: topk parameter is deprecated, use top_k instead\n",
      "  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2651623785495758, 'start': 38, 'end': 48, 'answer': '6000 hours'},\n",
       " {'score': 0.22082938253879547,\n",
       "  'start': 16,\n",
       "  'end': 48,\n",
       "  'answer': '1 MB/minute, so about 6000 hours'},\n",
       " {'score': 0.10253461450338364,\n",
       "  'start': 16,\n",
       "  'end': 27,\n",
       "  'answer': '1 MB/minute'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can do all that by simply importing the model as a pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "pipe(question=question, context=context, topk=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with long passages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the standard way to deal with the problem of having inputs larger than what the model can support is to apply a sliding window across the inputs, where each window contains a passage of tokens that fit in the model’s context.\n",
    "\n",
    "we can set return_overflowing_tokens=True in the tokenizer to enable the sliding window. The size of the sliding window is controlled by the max_seq_length argument, and the size of the stride is controlled by doc_stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\n",
    "tokenized_example = tokenizer(example[\"question\"], example[\"context\"], return_overflowing_tokens=True, max_length=100, stride=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window #0 has 100 tokens\n",
      "Window #1 has 88 tokens\n"
     ]
    }
   ],
   "source": [
    "for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n",
    "    print(f\"Window #{idx} has {len(window)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_example.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP] \n",
      "\n",
      "[CLS] how is the bass? [SEP] and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for window in tokenized_example[\"input_ids\"]:\n",
    "    print(f\"{tokenizer.decode(window)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Haystack to build a QA Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our QA system, we’ll use the Haystack library developed by deepset, a German company focused on NLP. Haystack is based on the retriever-reader architecture, abstracts much of the complexity involved in building these systems, and integrates tightly with Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initializing a document store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Haystack, there are various document stores to choose from and each one can be paired with a dedicated set of retrievers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It won't be possible to continue this chapter because the security restrictions of my computer does not allow me to start elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from subprocess import Popen, PIPE, STDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-darwin-x86_64.tar.gz\"\"\"\n",
    "# !wget -nc -q {url}\n",
    "# !tar -xzf elasticsearch-7.9.2-darwin-x86_64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "# from time import sleep\n",
    "# import requests\n",
    "\n",
    "# # Define the path to the Elasticsearch executable\n",
    "# elasticsearch_path = './elasticsearch-8.14.1/bin/elasticsearch'\n",
    "\n",
    "# # Start Elasticsearch as a background process\n",
    "# es_process = subprocess.Popen([elasticsearch_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# # Allow some time for Elasticsearch to start\n",
    "# sleep(30)\n",
    "\n",
    "# # Verify Elasticsearch is running\n",
    "# try:\n",
    "#     response = requests.get('http://localhost:9200')\n",
    "#     if response.status_code == 200:\n",
    "#         print(\"Elasticsearch is running\")\n",
    "#     else:\n",
    "#         print(\"Failed to start Elasticsearch\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error connecting to Elasticsearch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that our Elasticsearch server is up and running, the next thing to do is instantiate the document store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "\n",
    "# Return the document embedding for later use with dense retriever\n",
    "document_store = ElasticsearchDocumentStore(return_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, df in dfs.items():\n",
    "    # Exclude duplicate reviews\n",
    "    docs = [{\"text\": row[\"context\"],\n",
    "             \"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\n",
    "                     \"split\": split}}\n",
    "            for _,row in df.drop_duplicates(subset=\"context\").iterrows()] \n",
    "    \n",
    "    document_store.write_documents(docs, index=\"document\")\n",
    "    \n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initializing a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "\n",
    "# using the BM25 by default\n",
    "es_retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\"\n",
    "retrieved_docs = es_retriever.retrieve(query=query, top_k=3, filters={\"item_id\":[item_id], \"split\":[\"train\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieved_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "max_seq_length, doc_stride = 384, 128\n",
    "reader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False, max_seq_len=max_seq_length, doc_stride=doc_stride, return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reader.predict_on_texts(question=question, texts=[context], top_k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, es_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_answers = 3\n",
    "preds = pipe.run(query=query, top_k_retriever=3, top_k_reader=n_answers, filters={\"item_id\": [item_id], \"split\":[\"train\"]})\n",
    "print(f\"Question: {preds['query']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(n_answers):\n",
    "    print(f\"Answer {idx+1}: {preds['answers'][idx]['answer']}\")\n",
    "    print(f\"Review snippet: ...{preds['answers'][idx]['context']}...\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Our QA Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
