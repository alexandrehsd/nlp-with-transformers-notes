{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we are going to build our own encoder-decoder model to condense dialogues between several people into a crisp summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CNN/DailyMail Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN/DailyMail dataset consists of around 300,000 pairs of news articles and their corresponding summaries, composed from the bullet points that CNN and the DailyMail attach to their articles.\n",
    "\n",
    "The summaries are abstractive instead of extractive, meaning that it doesn't necessarily extract exact sentences from the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e386ed86fd654346a00eb87220ab5201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17713cd4612a425eb655aedb4969df8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097cfb24ab294fe081e494a60fc983d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8380968ffcbf44f19956b97148faffe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95b5fbc8d8d40b78cdc3b63719bc90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f5ed202abe4204bddc2e3a65f8be55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ce09a7ec7342c2adc8baaf617145c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae9fa1bc21b4867bad6ff78448622b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"Article (excerpt of 500 characters, total length: {len(sample['article'])}):\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's restrict the input text to 2,000 characters to have the same input for all models and thus make the outputs more comparable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventionally, sentences are separated by a newline when doing summarization. To help us with that, we'll use NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alexandre.dias/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline will be a model that takes the first three sentences of an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 can be used for text summarization by simply appending \"TL;DR\" at the end of the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the \\'forgotten floor\\' Â» . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "\n",
    "summaries[\"gpt2\"] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the T5 developers performed a comprehensive study of transfer learning in NLP and found they could create a universal transformer architecture by formulating all tasks as text-totext tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2169738f5724489b2b25982e6e3e17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa20c27a45d54241a1bf018b0afce40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d1fced453b496d8352c0f5e0400788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dac9e7ffcf4581a0de008ddbfc0142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38d580151ae42f69e56d40b87c727dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd08acb6a54475da11e0fdb11574896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-small\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART also uses an encoder-decoder architecture and is trained to reconstruct corrupted inputs. It combines the pretraining schemes of BERT and GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-base\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGASUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like BART, PEGASUS is an encoder-decoder transformer. Its pretraining objective is to predict masked sentences in multisentence texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is too big (2.28 GB)\n",
    "# pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "# pipe_out = pipe(sample_text)\n",
    "# summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Different Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n",
      "\n",
      "GPT2\n",
      "\n",
      "The prison in jail that serves the mentally ill is a mental health facility with 12,000 inmates.\n",
      "It was founded by psychiatrist Dr. Daniel M. Dufour, who was born in New Orleans by his parents when he was 12.\n",
      "The prison is not just overcrowded: it has been labeled a death camp.\n",
      "According to the U.S. Department of Justice, about\n",
      "\n",
      "T5\n",
      "inmates with most severe mental illnesses are incarcerated until they're ready to appear in court .\n",
      "most often, they face drug charges or charges of assaulting an officer .\n",
      "they end up on the ninth floor severely mentally disturbed, but not getting real help .\n",
      "\n",
      "BART\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"Forgotten floor.\"\n",
      "Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court.\n",
      "Most often, they\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Quality of Generated Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the most common metrics used to evaluate generated text are BLEU and ROUGE. Letâ€™s take a look at how theyâ€™re defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BLEU score is widely used for evaluating text, especially in machine translation, since precise translations are usually favored over translations that include all possible and appropriate words.\n",
    "\n",
    "There are other applications, such as summarization, where the situation is different. There, we want all the important information in the generated text, so we favor high recall. This is where the ROUGE score is usually used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROUGE score was specifically developed for applications like summarization where high recall is more important than just precision. Its final version is modified to appear more with a F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.252252</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.234234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.124138</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.252252  0.018349  0.144144   0.234234\n",
       "t5        0.195652  0.022222  0.108696   0.173913\n",
       "bart      0.326531  0.124138  0.176871   0.285714"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "    \n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating BART on the CNN/DailyMail Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.389276</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.245061</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.389276  0.171296  0.245061   0.354239"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement the same evaluation function for evaluating the BART model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "        \n",
    "        \n",
    "def evaluate_summaries_bart(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "    \n",
    "    for article_batch, target_batch in tqdm(zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                                   attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                                   length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries]\n",
    "        \n",
    "        decoded_summaries = [\"\\n\".join(sent_tokenize(d)) for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "        \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = evaluate_summaries_bart(test_sampled, rouge_metric, model, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "# pd.DataFrame(rouge_dict, index=[\"bart\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Summarization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1310419ffe4496a70b783e64e5ce77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddbd49a561745babb293bd02cf01294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f7af57afef44de8ab857f752b32b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5e3bb563d74116844bb92a44561536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [14732, 819, 818]\n",
      "Features: ['id', 'dialogue', 'summary']\n",
      "\n",
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")\n",
    "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
    "\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating BART on SAMSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how bart would perform on the last example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Hannah: Hey, do you have Betty's number?Amanda: Lemme check it out.Hannah?Hannah.\n",
      "<file_gif>What's her number?Is it her?Am Amanda: Sorry, can't find it.Is her number yours?Is your number hers?Is her phone mine?Is my number hers?\n",
      "?Is it hers?Handa: He called her last time we were at the park together.Is my phone hers?\n",
      "Hannah: I don't know him well.Is his number hersAmanda?Is his phone mine?\n",
      "?Hannah; Don't be shy,\n"
     ]
    }
   ],
   "source": [
    "pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"Summary:\")\n",
    "print(\"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's run a full evaluation on the samsum dataset\n",
    "# score = evaluate_summaries_bart(dataset_samsum[\"test\"], rouge_metric, model, tokenizer, column_text=\"dialogue\", column_summary=\"summary\", batch_size=8)\n",
    "# rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "# pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=40, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most dialogues are much shorter than the CNN/DailyMail articles, with 100â€“200 tokens per dialogue. Similarly, the summaries are much shorter, with around 20â€“40 tokens (the average length of a tweet).\n",
    "\n",
    "Now, we are going to tokenize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f9d8c5e82a4047bbb8175b8040774c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1d3088043f405fa16fdb3fb5a8fc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897f0289e9fb48d69e6fa0c1d5d723ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128, truncation=True)\n",
    "        \n",
    "    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
    "            \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "            \"labels\": target_encodings[\"input_ids\"]}\n",
    "    \n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched=True)\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create the data collator. This function is called in the Trainer just before the batch is fed through the model. In most cases we can use the default collaâ€ tor, which collects all the tensors from the batch and simply stacks them. For the summarization task we need to not only stack the inputs but also prepare the targets on the decoder side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.dias/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='bart-samsum', \n",
    "    num_train_epochs=1, \n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=1, \n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, \n",
    "    logging_steps=10, \n",
    "    push_to_hub=False,\n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=500, \n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  tokenizer=tokenizer, \n",
    "                  data_collator=seq2seq_data_collator, \n",
    "                  train_dataset=dataset_samsum_pt[\"train\"], \n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_summaries_bart(dataset_samsum[\"test\"], \n",
    "                                rouge_metric, \n",
    "                                trainer.model, \n",
    "                                tokenizer, \n",
    "                                batch_size=2, \n",
    "                                column_text=\"dialogue\", \n",
    "                                column_summary=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[f\"bart-samsum\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
